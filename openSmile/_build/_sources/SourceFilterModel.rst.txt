.. _sec1:

===========================
ソースフィルターモデル
===========================

:author: qh73xe
:Last Change: 25-May-2024.

.. contents::
    :depth: 2


.. _sec1cap0:

このパートで行うこと
===========================

- 音を音響特徴量に分解する感覚を掴む
- 基本周波数がどのようなものか理解する
- スペクトログラムがどのようなものか理解する
- 分解した音響特徴量から音声を再合成できる


.. _sec1cap1:

はじめに
===========================

:ref:`前章<sec0>` では, このドキュメントのテーマである OpenSmile は,
音に対するリトマス試験紙みたいなものであると述べました.
ここで, pH の意味を理解するためには,
そもそも酸性とかアルカリ性とかの概念を理解していなければなりません.
同様に, OpenSmile が算出する音響特徴量がなんであるのかを理するためには,
その基本要素を把握する必要があります.

音, ないし音声の基本要素を説明する概念に,
ソースフィルターモデルがあります.
このモデルを模式的に表現すると, 以下のようになります.

.. figure:: ./fig/sfmodel.png
   :align: center

   ソースフィルターモデル

ソースフィルターモデルでは,
人の発音メカニズムを管楽器として捉えます.
管楽器には, 大きく, リード (音源, ソース) と共鳴管 (フィルター) の 2 つの要素があります.
そのため, 発声された音から, 音源の情報と, 共鳴管の情報を分離することができれば,
音の性質を理解することができるだろうという考え方です.

それでは, 早速, 音声ファイルから,
音源の情報と共鳴管の情報を取得, 観察してみましょう.

.. _sec1cap2:

この章を試すための環境構築
============================

この章を試すためには, 以下のライブラリが必要です::

    $ pip install setuptools wheel ipython # python 用インタラクティブシェル
    $ pip install numpy scipy matplotlib pandas  # 数値計算用及び可視化ライブラリ
    $ pip install pyworld  # 最も基本的な音響解析ツール

Google Colab で実行する場合は, まず, 新規ノートブックを作成し以下のセルを実行してください::

    !pip install pyworld

.. _sec1cap3:

音声を録音する (Praat 編)
===========================

さて, 解析を行うためにはまず, 音声データが必要です.
後の章では, :code:`python` コードから録音を行う方法を紹介する予定ですが,
少し複雑なので, とりあえず, :code:`Praat` から音声を録音することにしましょう.

録音は Praat を開いて :code:`New` > :code:`Record mono sound` から行います.
新規にウィンドウが開かれるので :code:`Record` ボタンを押して録音を開始します.
`Stop` ボタンを押すと :code:`Save to list` というボタンが活性化されます.
これを押すと, メインウィンドウに録音した音声が表示されます.
最後に :code:`Save` > :code:`Save as WAV file` で音声を保存します.

.. warning::

    ここでは必ず, :code:`mono sound` で録音を行ってください.
    このチュートリアルでは, モノラル音声専用の解説を行います.
    ステレオ音声をどのように解析するのかについては,
    ご自身で調べてみてください.

音声ファイルの保存先は :ref:`前章<sec0cap3>` で作成した :code:`OpenSmileTutorial` ディレクトリに,
:code:`sample1.wav` という名前で保存してください.

:download:`sample1.wav <./wav/sample1.wav>`.

.. note:: Google Colab の場合, 前章で作成したディレクトリに音声ファイルをアップロードしてください.


.. _sec1cap4:

World を用いて基本的な音響特徴量を把握する
======================================================

さて, それでは早速解析をしていきましょう.
先にも述べたとおり, 基本的には, リトマス試験紙です.
これを利用する手順は大きく以下の 4 つです.

0. 試験紙を用意する = 解析用のライブラリを読み込む
1. 観察したい標本を取得する = 音声ファイルを読み込む
2. 試験紙につける = 音声ファイルから音響特徴量を抽出する
3. 色を見る = 音響特徴量を観察する

それでは, 作業を開始しましょう::

    $ ipython

.. note:: 

    このチュートリアルでは,
    まず, やりたいことを対話型 Shell で試し,
    その後, コードとして保存します.

    :code:`python` コマンドも対話型 Shell なのですが,
    補完機能等の利便性から, このチュートリアルでは :code:`ipython` を利用します.


.. _sec1cap41:

録音した音声を読み込む
------------------------------------------------------

まず試験紙を用意します::

    In [1]: import pyworld as pw
    In [2]: import numpy as np
    In [3]: from scipy.io import wavfile

:code:`pw` が試験紙です, :code:`wavfile` は音声ファイルを読み込むための,
スポイトみたいなものだと思ってください.

で :code:`wavfile` を利用して, 解析対象を読み込みましょう::

    In [4]: fs, x = wavfile.read("./sample1.wav")
    In [5]: x = x.astype(np.float64)

.. note:: 

   Google Colab で実行する場合は, まず Google Drive にアクセスする必要があります.
   以下のコードを実行して, Google Drive にアクセスしてください::

       from google.colab import drive
       drive.mount('/content/drive')

    その後左側にあるファイルアイコンをクリックし, ドライブ上のファイルを右クリックします.
    最後に 「パスをコピー」 を選択し, 上のコード :code:`./sample1.wav` の部分を置き換えてください::

    In [4]: fs, x = wavfile.read("/content/drive/MyDrive/OpenSmileTutorial/sample1.wav")
    In [5]: x = x.astype(np.float64)

第一引数には, 読み込みたい音声ファイルのパスを指定します.
帰値は 2 つあります. :code:`fs` と :code:`x` です.
それぞれ値を見てみましょう::

    In [6]: fs
    Out [6]: 44100

    In [7]: x
    Out[7]: array([-78., -67., -73., ...,   0.,   0.,   0.])

:code:`x` は array であることが分かりますね.
音声は一次元の波であるので, これがその波の値であると予想が着くと思います.
では, :code:`fs` はなんでしょうか?

これは詳しくは 4 章で説明をしますが,
サンプリング周波数と呼ばれるものです.
ざっくり言えば, 音をデジタル化するときに, どの程度, 緻密に記録しているかを
示す値です. この値が大きいほど, 音声の高域成分を記録することができます.
この値によっては, 試験紙が上手く機能しないこともあるので,
音声ファイルによってはとても重要な値です.

さて, 標本を取得したあとにやることは,
試験紙につけることです.
これは以下のように行います::

    In [8]: _f0, t = pw.dio(x, fs)
    In [9]: f0 = pw.stonemask(x, _f0, t, fs)
    In [10]: sp = pw.cheaptrick(x, f0, t, fs)
    In [11]: ap = pw.d4c(x, f0, t, fs)


試験紙につけると, 3 つの値が得られます.
それぞれ, 基本周波数 (:code:`f0`), スペクトル (:code:`sp`), 非周期成分 (:code:`ap`) です.
このチュートリアルでは, 音声からソースの成分とフィルターの成分を
取り出てざっくり観察することが目的なので,
以下では, ソースの成分である基本周波数 :code:`f0` と,
フィルターの成分であるスペクトル :code:`sp` を観察していきます.

.. _sec1cap42:

基本周波数を表示してみる
------------------------------------------------------

まず, 基本周波数から確認をしていきましょう::

    In [12]: f0
    Out[12]:
    array([  0.        ,   0.        ,   0.        ,   0.        ,
             0.        ,   0.        ,   0.        ,   0.        ,
 
基本周波数は一次元の配列であることが分かります.
基本周波数は, ソースとフィルターで言えば, ソースの成分に当たります.
大まかには, 声の高さを示す指標であり,
音声の場合, 声道の振動数に対応します.

数字の羅列を眺めていても, あまりイメージが沸かないと思うので,
可視化をしてみましょう::

    In [13]: from matplotlib import pylab as plt
    In [14]: plt.plot(t, f0)
    In [15]: plt.show()

.. figure:: ./fig/f0.png
   :align: center

   基本周波数

この図は, 横軸に時間, 縦軸に基本周波数を取ったグラフです.
ところどころ, 0 が入っていますね.

f0 は声帯の振動数を示す指標なので,
基本的には, 有声区間のみに, 値が入ります.
値が高いと, 振動が速い, つまり高い音になりますし,
値が低いと, 低い音になります.

.. note:: やってみよう

   自身の中で高い声, 低い声を録音してみてください.
   その上で, その差が本当に存在するのかを確認してみてください.

   なお, 平均は :code:`f0.mean()`, 標準偏差は :code:`f0.std()` で取得できます.


さて, 上の実習は, 実は意地悪な問題です.
なぜなら, pyworld において, 基本周波数が存在しない場合には 0 が入るからです.
つまり, 単純に :code:`f0.mean()` をみていると,
無音が多ければ多いほど必然的に値が低くなってしまいます.

正くは以下のように 0 の値を除外してから平均をとる必要があります::

    In [16]: f0[f0 != 0].mean()

.. _sec1cap43:

スペクトログラムを表示してみる
------------------------------------------------------

次に, フィルター側の成分である :code:`sp` を観察していきましょう::

    In [17]: sp
    Out[17]:
    array([[1.27474477e+05, 1.27628572e+05, 1.28091659e+05, ...,
            6.91549821e-01, 6.80848858e-01, 6.77286016e-01],
           [2.00391066e+06, 2.11805528e+06, 2.31736405e+06, ...,
            9.17460089e-02, 7.23594049e-02, 6.56105076e-02],
           [1.15332170e+06, 1.19652782e+06, 1.29128868e+06, ...,
            3.09766241e-01, 3.92445544e-01, 4.21223603e-01],
           ...,
           [6.76127005e+05, 6.89757063e+05, 7.16057589e+05, ...,
            2.80652722e+02, 3.08543893e+02, 3.15783837e+02],
           [1.22271414e+06, 1.26550533e+06, 1.34704831e+06, ...,
            3.28585317e+01, 3.09581823e+01, 2.93454583e+01],
           [1.53381403e+06, 1.60271369e+06, 1.75388809e+06, ...,
            1.23611930e+01, 1.31685075e+01, 1.32557763e+01]])

スペクトル成分は, 多次元の配列になります.
まず, 配列の次元数を確認してみましょう::

    In [18]: sp.shape
    Out[18]: (3185, 1025)

    In [19]: t.size
    Out[19]: 3185

結果を確認すると, 縦方向に時間軸が入っており,
横方向に 1025 次元の特徴量が入っていることが分かります.

これは, すごく乱暴な説明をすれば,
1025 個の穴のあいた楽器のそれぞれの音の大きさを時間軸に沿って並べたものです.
これを数で理解するのは難しいので, 画像として表示してみましょう::

    In [20]: plt.imshow(np.log(sp).T, aspect='auto', origin='lower')
    In [21]: plt.show()


.. figure:: ./fig/sp.png
   :align: center

   スペクトログラム

この図は, 横軸に時間, 縦軸に周波数を取ったグラフです.
黄色になると, その成分が大きく,
青色になると, その成分が小さいことを示しています.

図をよく観察すると, 発音を行っている部分には,
何か帯のようなものが現れていることが分かります.

この帯の形は, 大まかには, 舌の位置など
声道の形状によって変化します.

.. _sec1cap45:

音響特徴量の合成をしてみる
------------------------------------------------------

ここまでは, 音の特性というものは,
ソースの特性とフィルターの特性に分解できるということを
説明し, それぞれの特性の値を計測する方法について説明しました.

ただ, 本当に, この二つで音について説明ができるのか,
疑問があるかもしれません.

この章の最後の話題として, 音声の再合成を行ってみようと思います.
上の例で, :code:`f0` も :code:`sp` も, 単なる数字の配列であることを確認しました.
ここでは, これらの値を使って, 新しい音声ファイルを作成してみようと思います.

:code:`f0` や :code:`sp` などから, 音声波形を合成するには,
以下の関数を利用します::

    In [22]: y = pw.synthesize(f0, sp, ap, fs)
    In [23]: y = y.astype(np.int16)
    In [24]: wavfile.write("result.wav", fs, y)

.. note:: Google Colab の場合, 保存先を変更してください::

    In [24]: wavfile.write("/content/drive/MyDrive/OpenSmileTutorial/result.wav", fs, y)

22 行目で :code:`f0` や :code:`sp` など ( :code:`ap` も利用する必要がありますが) から,
音声波形を作成しています.

これは波形データですので, :code:`x` と同様に一次元の数値の配列です::

    In [25]: y
    Out[25]: array([-12, -12, -12, ...,   1,  12,   8], dtype=int16)

24 行目では, その波形データを :code:`wav` 形式のファイルとして保存しています.
第一引数には, wav ファイルの保存先を指定します.
第二引数には, サンプリング周波数を指定します.
第三引数には, wav ファイルとして保存したい波形データを指定します.

さて, 上のコードを実行すると, :code:`result.wav` というファイルが生成されます.
これは, 元の x を利用せず, :code:`f0` や :code:`sp` から機械的に合成された音声ファイルです.
早速, このファイルを聞いてみましょう.

どうでしょうか?
部分的に多少違和感のある箇所はあると思いますが,
さも, 人間が発音した音声のように聞こえるのではないでしょうか?

この実験から,
:code:`f0` や :code:`sp` などソースとフィルターの情報は,
実際の音声波形がなくとも,  元の波形を再現できる程度の情報を持っていることが分かります.

.. _sec1cap5:

この章のまとめ
======================================================

この章では, 音響解析の基本になるソースフィルターモデルについて説明しました.
音声の特徴は, ソースとフィルターの 2 つの要素に分解できるということを説明し,
それぞれを実際に取り出す方法について説明しました.
これらの値を簡単に観察し, それらを利用して音声を再合成する方法についても説明しました.

.. _sec1cap6:

次の章に向けて
======================================================

:code:`f0` や :code:`sp` には元の音声を再現できる程度に十分な情報が含まれていることは,
お伝えできたと思います.

ただ, です, 基本周波数や, スペクトル成分は, 少し問題があります.
それは, 特にスペクトル成分に関してなのですが,
解釈が難しいという点です.

例えば, 「スペクトル成分の第 18 次元を大きなるように発話をしてください」と言われても,
どうすればいいのか分かりません.

次章では, この問題に対する解決策として :code:`openSmile` を紹介します.
